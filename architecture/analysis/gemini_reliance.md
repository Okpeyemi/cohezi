# üéØ Analyse de D√©pendance : Gemini-Core

## Question : Le projet respecte-t-il l'utilisation de Gemini comme coeur ?
**R√©ponse : Actuellement, partiellement.** 

### Situation Actuelle
Le syst√®me utilise Gemini pour l'orchestration, l'analyse multi-agents et la synth√®se. Cependant, l'impl√©mentation actuelle pourrait √™tre port√©e sur d'autres mod√®les (GPT-4o, Claude 3.5) sans changement structurel majeur, car elle repose sur des appels JSON standard.

### Pourquoi Gemini 2.0/3 est le moteur id√©al pour Cohezi ?
1. **Context Window Massive** : Gemini permet de garder en m√©moire des centaines de pages de contexte (historique de d√©cision, th√©ories cognitives complexes) l√† o√π d'autres saturent.
2. **Flash Speed vs Reasoning** : L'utilisation de `gemini-2.0-flash` permet une orchestration parall√®le ultra-rapide (indispensable pour 5 agents en temps r√©el).
3. **Structured Output Natif** : Gemini 2.0 a une fid√©lit√© exceptionnelle aux sch√©mas JSON complexes, ce qui est le squelette de notre Arena.

---

## üèóÔ∏è Strat√©gie de "Verrouillage" (Gemini-Core Enforcement)

Pour rendre Gemini **irrempla√ßable** dans Cohezi, nous allons impl√©menter :

### 1. Raisonnement R√©cursif D√©pendent (Gemini-Specific)
Au lieu d'appels 100% parall√®les, nous allons cr√©er des d√©pendances :
- L'agent **Sceptique** examine les `findings` de l'agent **Logique** en temps r√©el.
- Cette cha√Æne de pens√©e profite de la vitesse de Gemini 2.0 Flash pour rester r√©active.

### 2. Inner-Monologue JSON (Double validation)
Forcer Gemini √† produire un champ `"rationale_chain_of_thought"` cach√© dans chaque r√©ponse JSON. Cela utilise la capacit√© de raisonnement √©tendue (CoT) de Gemini pour am√©liorer la qualit√© des `findings`.

### 3. Exploitation du Context Cache
Pr√©-charger les th√©ories de psychologie cognitive et de logique formelle dans le contexte de Gemini (via System Instructions massives) pour que les analyses ne soient pas g√©n√©riques, mais bas√©es sur des frameworks que seul Gemini peut g√©rer efficacement √† grande √©chelle.

### 4. Feed-forward Synthesis
La synth√®se finale ne se contentera pas de lire les rapports, elle "re-discutera" avec l'orchestrateur les points de conflit identifi√©s, cr√©ant un cycle de r√©flexion que seul un mod√®le √† haute fen√™tre de contexte peut maintenir sans perte d'information.

---

## üìê Architecture au Service de Gemini (Coding Standards)

Pour que Gemini reste le coeur efficace du syst√®me, l'architecture doit respecter des contraintes de propret√© strictes :

### 1. Granularit√© Extr√™me (Atomic Prompts)
- **R√®gle** : Aucun fichier de code ou de prompt ne doit √™tre massif. 
- **M√©triques** : Limite stricte de **150 √† 200 lignes par fichier**. 
- **B√©n√©fice** : Des fichiers courts permettent √† l'IA d'analyser le code plus vite et avec plus de pr√©cision lors des phases de maintenance ou d'√©volution ("Contextual Precision").

### 2. D√©coupage en Micro-Services Internes
- L'orchestration doit √™tre isol√©e dans une couche de service d√©di√©e (`backend/services/`). 
- Cela √©vite la dilution de la logique Gemini dans le transport HTTP (API routes), rendant le "coeur" IA plus pur et robuste.

### 3. Modularit√© du Triptyque
- Le frontend doit √™tre √©clat√© en composants atomiques (`AgentCard`, `CausalSVG`, `VerdictSidebar`).
- Cela permet d'injecter des optimisations sp√©cifiques √† Gemini (ex: streaming de texte, feedback loops) sans impacter l'ensemble de l'application.
